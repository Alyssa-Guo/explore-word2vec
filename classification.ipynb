{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "from gensim.models import word2vec\n",
    "import re\n",
    "import logging\n",
    "import copy\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "\t#assume all reveiws written in english, delete all non-ascii char\n",
    "\ttext = text.encode('ascii','ignore').decode()\n",
    "\t\n",
    "\t#delete HTML tag\n",
    "\ttext = re.sub(r'</?\\w+[^>]*>','',text)\n",
    "\t\n",
    "\t#delete punctuation except char'char case(e.g. \"haven't\",\"can't\",\"macy's\")\n",
    "\ttext = re.sub(\" '|'\\W|[-(),.\\\"!?#*$~`\\{\\}\\[\\]/+&*=:^]\", \" \", text)\n",
    "\t\t\n",
    "\t#transform several space into one space\n",
    "\ttext = re.sub(\"\\s+\", \" \", text)\n",
    "\t\t\n",
    "\t#transform all letters to lowercase\n",
    "\ttext = text.lower().split()\n",
    "\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createInput(neg_path, pos_path):\n",
    "\t#\n",
    "\t#Gensim's word2vec input format is a list of lists, each list inside the list indicates a review. \n",
    "\t#[['word1', 'word2', 'word3', '...'],['word1', 'word2', '...'], ..., ['...','...']]\n",
    "\t#\n",
    "\n",
    "\tprint(\"Loading the imdb reviews data and clean the data\")\n",
    "\tneg_files = glob.glob(neg_path + \"/*.txt\")\n",
    "\tpos_files = glob.glob(pos_path + \"/*.txt\")\n",
    "\t\n",
    "\tsentences = []\n",
    "\ty = []\n",
    "\t\n",
    "\tfor tnf in neg_files:\n",
    "\t\tf = open(tnf, 'r', errors='replace')\n",
    "\n",
    "\t\tline = f.read()\n",
    "\n",
    "\t\t#clean the data by delete punctuations and transform all uppercase to lowercase\n",
    "\t\tclean_line = cleanText(line)\n",
    "\t\t\n",
    "\t\tsentences.append(clean_line)\n",
    "\n",
    "\t\t#also generate corresponding y label\n",
    "\t\ty.append(0)\n",
    "\t\t\n",
    "\t\tf.close()\n",
    "\t\n",
    "\tfor tpf in pos_files:\n",
    "\t\tf = open(tpf, 'r', errors='replace')\n",
    "\t\tline = f.read()\n",
    "\t\tclean_line = cleanText(line)\n",
    "\t\tsentences.append(clean_line)\n",
    "\t\ty.append(1)\n",
    "\t\tf.close()\n",
    "\t\n",
    "\tprint(\"Data loaded and cleaned.\")\n",
    "\n",
    "\treturn sentences, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainModel(sentences):\n",
    "\tlogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "\t\tlevel=logging.INFO)\n",
    "\n",
    "\t#set values for the parameters in Word2Vec\n",
    "\t#dimension: word vector dimensionality\n",
    "\tdimension = 200  \n",
    "\t#min_count: any word that does not occur at least this many times across all documents is ignored\n",
    "\tmin_count = 5\n",
    "\t#number of threads to run in parallel\n",
    "\tnum_workers = 4\n",
    "\t#window size  \n",
    "\twindow_size = 5\n",
    "\t#downsample setting for frequent words  \n",
    "\tdownsampling = 1e-3  \n",
    "\n",
    "\tprint(\"Training model\")\n",
    "\tmodel = word2vec.Word2Vec(sentences, workers=num_workers,\n",
    "\t\t\t\t\t\t\t  size=dimension, min_count=min_count,\n",
    "\t\t\t\t\t\t\t  window=window_size, sample=downsampling, sg = 1)\n",
    "\n",
    "\t#\n",
    "\t#If finished training a model (no more updates, only querying), \n",
    "\t#could do:\n",
    "\t# model.init_sims(replace=True)\n",
    "\t#to trim unneeded model memory = use (much) less RAM.\n",
    "\t#\n",
    "\n",
    "\t#save the model to disk\n",
    "\t#specify path and model's name\n",
    "\tpath = \"/Users/pguo/Desktop/try/\"\n",
    "\tfname = \"trained_model\"\n",
    "\tmodel.save(path+fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createFeature(x, model):\n",
    "\t#\n",
    "\t#use method that averaging the word vectors in each review\n",
    "\t#For example,\n",
    "\t#review: \"Amy is beautiful\"\n",
    "\t#\"Amy\" = [0.3, 0.6, 0.8]\n",
    "\t#\"is\" = [1.2, 3.5, 4.6]\n",
    "\t#\"beautiful\" = [0.9, 1.2, 8.7]\n",
    "\t#then the vector of the review \n",
    "\t#= [(0.3 + 1.2 + 0.9)/3, (0.6 + 3.5 + 1.2)/3, (0.8 + 4.6 + 8.7)/3]\n",
    "\t#= [0.8, 1.77, 4.7]\n",
    "\t#\n",
    "\t\n",
    "\t#review_index indicates the ith review\n",
    "\treview_index = 0\n",
    "\t#number of features, equals to the dimension(colum) of model's vocabulary\n",
    "\tnum_features = model.syn0.shape[1]\n",
    "\tfeatures = np.zeros((len(x),num_features), dtype=np.float32)\n",
    "\n",
    "\t#model.index2word is a list of the names of the words in the model's vocabulary.\n",
    "\t#convert to set in order to increase the searching speed\n",
    "\tvocab = set(model.index2word)\n",
    "\n",
    "\tfor review in x:\n",
    "\t\t#total words in a review\n",
    "\t\ttotalwords = 0\n",
    "\t\tfor word in review:\n",
    "\t\t\tif word in vocab:\n",
    "\t\t\t\ttotalwords += 1\n",
    "\t\t\t\tfeatures[review_index] = np.add(features[review_index], model[word])\n",
    "\t\tfeatures[review_index] = np.divide(features[review_index],totalwords)\n",
    "\t\t#next review\n",
    "\t\treview_index += 1\n",
    "\treturn features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the imdb reviews data and clean the data\n",
      "Data loaded and cleaned.\n",
      "Training model\n",
      "Load Model\n",
      "create test data\n",
      "Loading the imdb reviews data and clean the data\n",
      "Data loaded and cleaned.\n",
      "classification\n",
      "Accuracy on test: 0.8245\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "#specify the path of datasets\n",
    "neg_path = \"/Users/pguo/Desktop/try/aclImdb/train/neg\"\n",
    "pos_path = \"/Users/pguo/Desktop/try/aclImdb/train/pos\"\n",
    "\n",
    "#first use training data create input of word2vector\n",
    "#also create the corresponding training label\n",
    "sentences, y_train = createInput(neg_path, pos_path)\n",
    "\n",
    "#save x_train for later use\n",
    "#in gensim, the x_train's format is same as the word2vec training model's input\n",
    "x_train = copy.deepcopy(sentences)\n",
    "\n",
    "#First use word2vec generate vector for each word\n",
    "#use word2vec train model\n",
    "trainModel(sentences)\n",
    "\n",
    "#classification\n",
    "#model's path\n",
    "path = \"/Users/pguo/Desktop/try/\"\n",
    "#model's name\n",
    "fname = \"trained_model\"\n",
    "#load model\n",
    "print(\"Load Model\")\n",
    "model = word2vec.Word2Vec.load(path+fname)\n",
    "\n",
    "#use word vector transform review to features\n",
    "train_features = createFeature(x_train, model)\n",
    "\n",
    "#create input of test data\n",
    "print(\"create test data\")\n",
    "neg_path = \"/Users/pguo/Desktop/try/aclImdb/test/neg\"\n",
    "pos_path = \"/Users/pguo/Desktop/try/aclImdb/test/pos\"\n",
    "x_test, y_test = createInput(neg_path, pos_path)\n",
    "\n",
    "#use word vector transform review to features\n",
    "test_features = createFeature(x_test, model)\n",
    "\t\n",
    "#classification\n",
    "print(\"classification\")\n",
    "clf=LogisticRegression(penalty='l1', C=0.1)\n",
    "clf.fit(train_features, y_train)\n",
    "print(\"Accuracy on test: %0.4f\" %clf.score(test_features, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
